import os
import inspect
import glob
import yaml


filename = inspect.getframeinfo(inspect.currentframe()).filename
chip_path = os.path.dirname(os.path.abspath(filename))
#
# configfile: "%s/config.yaml" % (chip_path)

if 'chip_align_config' in config:
    with open(config['chip_align_config']) as c:
        config.update(yaml.load(c))


## I feel dirty for doing this. But if "_" is in the srr_id,
## it will try to merge the controls. But if the source is local, the srr_id
## needs to match the filename so has to contain "_" when it is in the filename.
search_dict = {}
for celltype in config['experiment']:
    for experiment in config['experiment'][celltype]:
        exp_dict = config['experiment'][celltype][experiment]
        for target in exp_dict:
            for sample in exp_dict[target]:
                for type in ('treatment', 'control'):
                    id_list = exp_dict[target][sample][type]
                    for i in range(0,len(id_list)):
                        if '_' in id_list[i]:
                            new_id = id_list[i].replace('_', '-')
                            search_dict[new_id] = id_list[i]
                            id_list[i] = new_id


def format_bs(bs):
    kb = bs / 1000
    if kb >= 1:
        bin = '%gkb' % kb
    else:
        bin = '%ibp' % bs
    return(bin)

def parse_bs(bs):
    bs_num = float(bs[:-2])
    if bs.endswith('bp'):
        bin = int(bs_num)
    elif bs.endswith('kb'):
        bin = int(bs_num * 1000)
    return(bin)

def get_all(config):
    regex_bw = '%s/%s/tracks/%s/%s/%s/%s_%s_r%i_%s_fcoc.bw'
    regex_target_bw = '%s/%s/tracks/%s/%s/%s/%s_fcoc.bw'
    regex_sample_bw = '%s/%s/tracks/%s/%s/%s/%s_%s_fcoc.bw'
    regex_hmm = '%s/%s/hmm/%s/%s/%s/%s_%s.txt'
    regex_idx = '%s/%s/idxstats/%s/%s/%s_%s.txt'
    regex_np = '%s/%s/gff3/%s/%s/%s_%s_r%i_%s_%s.gff3'

    regex_corr = '%s/%s/stats/%s/%s/%s_%s_scatter.pdf'
    regex_target_corr = '%s/%s/stats/%s/%s/%s/%s_scatter.pdf'
    regex_all_corr = '%s/%s/stats/%s/%s/%s_scatter.pdf'
    for genome in config['chip_genome']:
        for celltype in config['experiment']:
            all_target_dict = {}
            for experiment in config['experiment'][celltype]:
                exp_dict = config['experiment'][celltype][experiment]
                for target in exp_dict:
                    target_dict = exp_dict[target]
                    bs_list = [bs for sample in target_dict
                               for bs in target_dict[sample]['track_bs']]
                    if target in all_target_dict:
                        all_target_dict[target].append(bs_list)
                    else:
                        all_target_dict[target] = [bs_list]

                    if len(target_dict) > 1:
                        for bs in bs_list:
                            yield(regex_target_bw % (config['chip_out'], genome,
                                                     celltype, experiment,
                                                     format_bs(bs),
                                                     target))
                            yield(regex_target_corr % (config['chip_out'], genome,
                                                       celltype, experiment,
                                                       format_bs(bs),
                                                       target))
                    for sample in target_dict:
                        info_dict = target_dict[sample]
                        width = info_dict['hiddendomain_width']
                        p = info_dict['hiddendomain_p']
                        domain = ['-'.join(('domains',str(w), str(p)))
                                  for w in width]
                        if target in ['CTCF', 'ParR']:
                            domain.append('narrowPeak')
                        rep_list = info_dict['treatment']
                        if 'hmmr' in info_dict:
                            for bs in info_dict['hmmr']:
                                yield(regex_hmm % (config['chip_out'], genome,
                                                   celltype, experiment,
                                                   format_bs(bs),
                                                   target, sample))

                        if len(rep_list) > 1:
                            if 'track_bs' in info_dict:
                                for bs in info_dict['track_bs']:
                                    yield(regex_corr % (config['chip_out'], genome,
                                                        celltype, experiment, target,
                                                        sample))
                                    yield(regex_sample_bw % (config['chip_out'], genome,
                                                             celltype, experiment,
                                                             format_bs(bs),
                                                             target, sample))
                        for rep in range(0, len(rep_list)):
                            if 'track_bs' in info_dict:
                                for bs in info_dict['track_bs']:
                                    yield(regex_bw % (config['chip_out'],
                                                      genome, celltype,
                                                      experiment,
                                                      format_bs(bs), target,
                                                      sample, rep+1,
                                                      rep_list[rep]))

                            for region in domain:
                                yield(regex_np % (config['chip_out'], genome,
                                                   celltype, experiment, target,
                                                   sample, rep+1,
                                                   rep_list[rep], region))
                        yield(regex_idx % (config['chip_out'], genome, celltype,
                                           experiment, target, sample))
            for target in all_target_dict:
                bs_list_list = all_target_dict[target]
                if len(bs_list_list) > 1:
                    for bs_list in bs_list_list:
                        for bs in bs_list:
                            yield(regex_all_corr % (config['chip_out'], genome,
                                                    celltype,
                                                    format_bs(bs), target))




rule all_chip_align:
    input:
        [out_file for out_file in get_all(config)]


rule plot_correlation:
    input:
        '{outdir}/stats/{path}.npz'
    output:
        '{outdir}/stats/{path}_scatter.pdf'
    params:
        cor_method=config['replicate_cor_method']
    shell:
        "plotCorrelation --corData {input} "
        "                --plotFile {output} "
        "                --corMethod {params.cor_method} "
        "                -p scatterplot"


rule hmmr:
    input:
        '{outdir}/tracks/{dir_name}_fcoc.bw'
    output:
        txt='{outdir}/hmm/{dir_name}.txt',
        gff='{outdir}/hmm/{dir_name}.gff3'
    shell:
        "{chip_path}/scripts/hmmr_domains.R --bw {input}"
        "                                   --gff {output.gff}"
        "                                   > {output.txt}"



def get_compare_all(config, wildcards):
    for celltype in config['experiment']:
        for experiment in config['experiment'][wildcards.celltype]:
            exp_dict = config['experiment'][wildcards.celltype][experiment]
            if wildcards.target in exp_dict:
                target_dict = exp_dict[wildcards.target]
                if len(target_dict) > 1:
                    yield('%s/tracks/%s/%s/%s/%s_fcoc.bw' % (wildcards.outdir,
                                                             wildcards.celltype,
                                                             experiment,
                                                             wildcards.bs,
                                                             wildcards.target))
                else:
                    for sample in target_dict:
                        yield('%s/tracks/%s/%s/%s/%s_%s_fcoc.bw' % (wildcards.outdir,
                                                                    wildcards.celltype,
                                                                    experiment,
                                                                    wildcards.bs,
                                                                    wildcards.target,
                                                                    sample))
rule compare_all:
    input:
        lambda wildcards: get_compare_all(config, wildcards)
    output:
        '{outdir}/stats/{celltype, [^/]+}/{bs}/{target, [^_]+}.npz'
    threads:
        10
    shell:
        "multiBigwigSummary bins --bwfiles {input}"
        "                        -p {threads}"
        "                        -out {output}"

def get_compare_bw(config, wildcards):
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    target_dict = exp_dict[wildcards.target]
    for sample in target_dict:
        rep_list = exp_dict[wildcards.target][sample]['treatment']
        if len(rep_list) > 1:
            yield('%s/tracks/%s/%s/%s/%s_%s_fcoc.bw' % (wildcards.outdir,
                                                        wildcards.celltype,
                                                        wildcards.experiment,
                                                        wildcards.bs,
                                                        wildcards.target,
                                                        sample))
        else:
            yield('%s/tracks/%s/%s/%s/%s_%s_r1_%s_fcoc.bw' % (wildcards.outdir,
                                                              wildcards.celltype,
                                                              wildcards.experiment,
                                                              wildcards.bs,
                                                              wildcards.target,
                                                              sample,
                                                              rep_list[0]))

rule compare_target:
    input:
        lambda wildcards: get_compare_bw(config, wildcards)
    output:
        '{outdir}/stats/{celltype}/{experiment}/{bs}/{target, [^_]+}.npz',
        '{outdir}/stats/{celltype}/{experiment}/{bs}/{target, [^_]+}.txt'
    threads:
        10
    wildcard_constraints:
        celltype='[^/]+',
        experiment='[^/]+',
        bs='[0-9]+[kb][bp]'
    shell:
        "multiBigwigSummary bins --bwfiles {input}"
        "                        -p {threads}"
        "                        -out {output[0]}"
        "                        --outRawCounts {output[1]}"


def get_compare_rep_bw(config, wildcards):
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    rep_list = exp_dict[wildcards.target][wildcards.sample]['treatment']
    for rep in range(0, len(rep_list)):
        yield('%s/coverage/%s/%s/%s/%s_%s_r%i_%s.bw' % (wildcards.outdir,
                                                        wildcards.celltype,
                                                        wildcards.experiment,
                                                        wildcards.bs,
                                                        wildcards.target,
                                                        wildcards.sample,
                                                        rep+1, rep_list[rep]))


rule make_compare_bw:
    input:
        '{outdir}/{genome}/stats/{path}.txt',
        "{outdir}/{genome}/chrom_sizes.txt"
    output:
        '{outdir}/{genome}/tracks/{path}_fcoc.bw'
    wildcard_constraints:
        genome="[^/]+",
    threads:
        5
    shell:
        "{chip_path}/scripts/bigWigCompare_to_bw.R -i {input[0]}"
        "                                          -cs {input[1]}"
        "                                          -t {threads}"
        "                                          -bw {output}"


def get_label(file_iter, add=['Input'], prefix='exp'):
    iter_list = [prefix for f in file_iter]
    for i in range(0, len(iter_list)):
        iter_list[i] = ''.join(iter_list)
    iter_list.extend(add)
    return(iter_list)


def get_input_name(config, celltype, experiment, target, sample):
    exp_dict = config['experiment'][celltype][experiment]
    srr_id = '_'.join(exp_dict[target][sample]['control'])
    return(srr_id)



def get_input_bw(config, wildcards, bam=False):
    srr_id = get_input_name(config, wildcards.celltype, wildcards.experiment,
                            wildcards.target, wildcards.sample)

    if 'genome' in wildcards.keys():
        if bam is True:
            pat_list = ['{outdir}/{genome}/filtered/control/{srr}.bam',
                        '{outdir}/{genome}/filtered/control/{srr}.bam.bai']
        else:
            pat_list = ['{outdir}/{genome}/coverage/control/{bs}/{srr}.bw']
    else:
        if bam is True:
            pat_list = ['{outdir}/filtered/control/{srr}.bam',
                        '{outdir}/filtered/control/{srr}.bam.bai']
        else:
            pat_list = ['{outdir}/coverage/control/{bs}/{srr}.bw']
    for pat in pat_list:
        yield(pat.format(srr=srr_id, **wildcards))


def get_input_bam(config, wildcards):
    srr_id = get_input_name(config, wildcards.celltype, wildcards.experiment,
                            wildcards.target, wildcards.sample)
    bam = '%s/%s/filtered/control/%s.bam' % (wildcards.outdir,
                                             wildcards.genome, srr_id)
    return([bam, ''.join([bam, '.bai'])])



rule compare_bw_rep:
    input:
        signal=lambda wildcards: get_compare_rep_bw(config, wildcards),
        input=lambda wildcards: get_input_bw(config, wildcards)
    output:
        '{outdir}/stats/{celltype}/{experiment}/{bs}/{target}_{sample}.npz',
        '{outdir}/stats/{celltype}/{experiment}/{bs}/{target}_{sample}.txt'
    params:
        label=lambda wildcards: get_label(get_compare_rep_bw(config, wildcards)),
        bs=lambda wildcards: parse_bs(wildcards.bs)
    threads:
        10
    wildcard_constraints:
        target="[^_]+",
        sample="[^_]+",
        celltype='[^/]+',
        experiment='[^/]+',
        bs='[0-9]+[kb][bp]'
    shell:
        "multiBigwigSummary bins --bwfiles {input.signal} {input.input}"
        "                        --label {params.label}"
        "                        -p {threads}"
        "                        -bs {params.bs}"
        "                        -out {output[0]}"
        "                        --outRawCounts {output[1]}"


def get_compare_bam(config, wildcards):
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    rep_list = exp_dict[wildcards.target][wildcards.sample]['treatment']
    for rep in range(0, len(rep_list)):
        yield('%s/filtered/%s/%s/%s_%s_r%i_%s.bam' % (wildcards.outdir,
                                                      wildcards.celltype,
                                                      wildcards.experiment,
                                                      wildcards.target,
                                                      wildcards.sample,
                                                      rep+1, rep_list[rep]))

rule compare_bam_replicates:
    input:
        bam=lambda wildcards: get_compare_bam(config, wildcards),
        bai=lambda wildcards: [''.join((name, '.bai')) for name in
                               get_compare_bam(config, wildcards)]
    output:
        '{outdir}/stats/{celltype}/{experiment}/{target}_{sample}.npz'
    threads:
        10
    shell:
        "multiBamSummary bins --bamfiles {input.bam} "
        "                     -bs 1000 "
        "                     -p {threads} "
        "                     -out {output} "


def get_exp(config, wildcards):
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    rep_list = exp_dict[wildcards.target][wildcards.sample]['treatment']
    for r in range(0,len(rep_list)):
        yield('%s/%s/filtered/%s/%s/%s_%s_r%i_%s.bam' % (wildcards.outdir,
                                                         wildcards.genome,
                                                         wildcards.celltype,
                                                         wildcards.experiment,
                                                         wildcards.target,
                                                         wildcards.sample,
                                                         r + 1, rep_list[r]))



def get_ctrl_input(config, wildcards):
    ip_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    srr_list = ip_dict[wildcards.target][wildcards.sample]['control']
    srr_str = '_'.join(srr_list)
    return('%s/%s/filtered/control/%s.bam' % (wildcards.outdir, wildcards.genome,
                                              srr_str))



rule idxstats:
    input:
        exp=lambda wildcards: get_exp(config, wildcards),
        ip=lambda wildcards: get_ctrl_input(config, wildcards),
        exp_bai=lambda wildcards: ['%s.bai' % (fname) for fname in
                                   get_exp(config, wildcards)],
        ip_bai=lambda wildcards: '%s.bai' % (get_ctrl_input(config, wildcards))
    output:
        '{outdir}/{genome}/idxstats/{celltype}/{experiment}/{target}_{sample}.txt'
    wildcard_constraints:
        target='[^_]+'
    shell:
        "{chip_path}/scripts/idxstats.R --exp {input.exp} "
        "                               --input {input.ip}"
        "                               --out {output}"






# ruleorder: bamcompare > coverage
#
# rule coverage:
#     input:
#         bam='mapping/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam',
#         bai='mapping/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam.bai'
#     output:
#         'tracks/{experiment}/{target}_{sample}_{rep}_{srr_id}.bw'
#     params:
#         min_mapq = config['min_mapq']
#     threads:
#         10
#     shell:
#         "bamCoverage --minMappingQuality {params.min_mapq} "
#         "            -bs 1 "
#         "            -p {threads} "
#         "            -b {input.bam} "
#         "            -o {output} "

rule chrom_sizes:
    input:
        lambda wildcards: config['chrom_sizes'][wildcards.genome]
    output:
        "{outdir}/{genome}/chrom_sizes.txt"
    shell:
        "awk -vOFS='\\t' '{{if ($1!=\"\" && $1!~/chrM/){{print $1, $2}}}}' {input} > {output}"


def convert_input(wildcards):
    if (wildcards.region.startswith('domains')):
        region = wildcards.region.split('-')
        regex = '_'.join(('%s/domains/%s/%s/%s_%s_r%s_%s', region[1], region[2],
                          'analysis.bed'))
    else:
        regex = '%s/peaks/%s/%s/%s_%s_r%s_%s_peaks.narrowPeak'
    return(regex % (wildcards.outdir, wildcards.celltype, wildcards.experiment,
                    wildcards.target, wildcards.sample, wildcards.rep,
                    wildcards.srr_id))

def get_source(wildcards):
    if (wildcards.region=='domains'):
        return('hiddenDomains')
    else:
        return('MACS2')

def get_data_type(config, wildcards):
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    return(exp_dict[wildcards.target][wildcards.sample]['SOFA'])

rule convert2gff:
    input:
        lambda wildcards: convert_input(wildcards)
    output:
        '{outdir}/gff3/{celltype}/{experiment}/{target}_{sample}_r{rep}_{srr_id}_{region}.gff3'
    params:
        source=lambda wildcards: get_source(wildcards),
        datatype=lambda wildcards: get_data_type(config, wildcards),
        o=lambda wildcards: '-n' if (wildcards.region=='narrowPeak') else ''
    shell:
        "{chip_path}/scripts/bed2gff.sh -s {params.source} -t {params.datatype}"
        "                               {params.o} -b {input} > {output}"


def get_peak_rep(config, wildcards):
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    srr_list = exp_dict[wildcards.target][wildcards.sample]['treatment']
    if wildcards.peaktype == 'peaks':
        regex = '%s/peaks/%s/%s/%s_%s_r%i_%s_peaks.narrowPeak'
        for r in range(0, len(srr_list)):
            yield(regex % (wildcards.outdir, wildcards.celltype,
                           wildcards.experiment, wildcards.target,
                           wildcards.sample, r + 1, srr_list[r]))
    else:
        regex = '%s/domains/%s/%s/%s_%s_r%i_%s_%s_%s_analysis.bed'
        for r in range(0, len(srr_list)):
            yield(regex % (wildcards.outdir, wildcards.celltype,
                           wildcards.experiment, wildcards.target,
                           wildcards.sample, r + 1, srr_list[r],
                           wildcards.bs, wildcards.p))



rule shared_peak:
    input:
        lambda wildcards: get_peak_rep(config, wildcards)
    output:
        '{outdir}/{peaktype}/{celltype}/{experiment}/{target}_{sample}_{bs}_{p}_shared.txt'
    shell:
        "{chip_path}/scripts/overlapping_peaks.R {input} > {output}"

def domain_width(config, wildcards):
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    width = exp_dict[wildcards.target][wildcards.sample]['hiddendomain_width']
    return(width)

rule call_domains:
    input:
        bam='{outdir}/{genome}/filtered/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam',
        bai='{outdir}/{genome}/filtered/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam.bai',
        ctrl=lambda wildcards: get_input_bw(config, wildcards, bam=True),
        g='{outdir}/{genome}/chrom_sizes.txt'
    output:
        '{outdir}/{genome}/domains/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}_{bs}_{p}_analysis.bed'
    params:
        o='{outdir}/{genome}/domains/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}_{bs}_{p}',
        b='{bs}',
        p='{p}'
    wildcard_constraints:
        target='[^_]+',
        sample='[^_]+',
        rep='r[0-9]+'
    shell:
        "export PATH={chip_path}/hiddenDomains/:$PATH;"
        "hiddenDomains -g {input.g} -t {input.bam} -c {input.ctrl[0]} "
        "              -b {params.b} -p {params.p} -o {params.o}"



rule call_peaks:
    input:
        bam='{outdir}/{genome}/filtered/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam',
        bai='{outdir}/{genome}/filtered/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam.bai',
        ctrl=lambda wildcards: get_input_bw(config, wildcards, bam=True)
    output:
        '{outdir}/{genome}/peaks/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}_peaks.narrowPeak'
    params:
        d='{outdir}/{genome}/peaks/{celltype}/{experiment}/',
        n='{target}_{sample}_{rep}_{srr_id}',
        g=config['macs2_gsize']
    conda:
        "envs/macs2.yaml"
    wildcard_constraints:
        target='[^_]+',
        sample='[^_]+',
        rep='r[0-9]+'
    shell:
        "macs2 callpeak -t {input.bam} -c {input.ctrl[0]} --outdir {params.d} "
        "               -n {params.n} -g {params.g} --keep-dup all --nomodel"







rule bamcompare:
    input:
        bw='{outdir}/{genome}/coverage/{celltype}/{experiment}/{bs}/{target}_{sample}_{rep}_{srr_id}.bw',
        ctrl=lambda wildcards: get_input_bw(config, wildcards)
    output:
        temp('{outdir}/{genome}/stats/{celltype}/{experiment}/{bs}/{target}_{sample}_{rep}_{srr_id}.npz'),
        '{outdir}/{genome}/stats/{celltype}/{experiment}/{bs}/{target}_{sample}_{rep}_{srr_id}.txt'
    log:
        '{outdir}/{genome}/log/tracks/{celltype}/{experiment}/{bs}/{target}_{sample}_{rep}_{srr_id}_fcoc.log'
    params:
        labels = '{target}_{sample}_{rep}_{srr_id}',
        min_mapq = config['min_mapq'],
        binsize = lambda wildcards: parse_bs(wildcards.bs)
    threads:
        10
    wildcard_constraints:
        target='[^_]+',
        sample='[^_]+',
        rep='r[0-9]+'
    shell:
        "multiBigwigSummary bins --bwfiles {input.bw} {input.ctrl}"
        "                        --labels {params.labels} Input"
        "                        -p {threads}"
        "                        -bs {params.binsize}"
        "                        -out {output[0]}"
        "                        --outRawCounts {output[1]} > {log} 2>&1"
        #
        # cmd=("bamCompare --minMappingQuality {params.min_mapq} "
        #      "           --operation ratio "
        #      "           --skipNAs "
        #      "           --pseudocount 0"
        #      "           -p {threads} "
        #      "           -bs {params.binsize}"
        #      "           -b1 {input.bam} "
        #      "           -b2 {input.ctrl[0]} "
        #      "           -of bigwig "
        #      "           --verbose"
        #      "           -o {output} > {log} 2>&1")
        # shell(' '.join(('echo "', cmd, '"; ',cmd)))

def get_control_id(config, wildcards):
    rep = int(wildcards.rep.replace('r', '')) - 1
    exp_dict = config['experiment'][wildcards.celltype][wildcards.experiment]
    srr_id = '_'.join(exp_dict[wildcards.target][wildcards.sample]['control'])
    return(srr_id)

def get_greylist(config, wildcards):
    srr_id = get_control_id(config, wildcards)
    return('%s/%s/greylist/%s-grey.bed' % (wildcards.outdir,
                                           wildcards.genome, srr_id))

# rule bw_pseudo:
#     input:
#         bw='{outdir}/{genome}/coverage/{name}.bw',
#         sizes='{outdir}/{genome}/chrom_sizes.txt'
#     output:
#         '{outdir}/{genome}/coverage/{name}_pseudo.bw'
#     shell:
#         "bigWigToWig {input.bw} /dev/stdout | "
#         "   awk -vOFS='\t' '{{print $1, $2, $3, $4 + 1}}' | "
#         "   wigToBigWig /dev/stdin {input.sizes}"

rule bw_coverage:
    input:
        bam='{outdir}/{genome}/filtered/{path}/{name}.bam',
        bai='{outdir}/{genome}/filtered/{path}/{name}.bam.bai',
        chromsize="{outdir}/{genome}/chrom_sizes.txt"
    output:
        '{outdir}/{genome}/coverage/{path}/{bs}/{name}.bw'
    params:
        binsize = lambda wildcards: parse_bs(wildcards.bs)
    threads:
        20
    shell:
        "{chip_path}/scripts/sambambaToBw.sh -t {threads}"
        "                                    -b {input.bam}"
        "                                    -o {output}"
        "                                    -w {params.binsize}"
        "                                    -c {input.chromsize}"


def use_grey(config, wildcards):
    use_grey = True
    if 'use_grey' in config:
        if 'srr_id' in wildcards.keys():
            srr_id = wildcards.srr_id
        else:
            srr_id = get_control_id(config, wildcards)
        if srr_id in config['use_grey']:
            use_grey = config['use_grey'][srr_id]
    return(use_grey)

rule filter_blackgrey_ctrl:
    input:
        bam='{outdir}/{genome}/mapping/control/{srr_id}.bam',
        grey='{outdir}/{genome}/greylist/{srr_id}-grey.bed',
        black=lambda wildcards: config['blacklist'][wildcards.genome]
    output:
        '{outdir}/{genome}/filtered/control/{srr_id}.bam'
    params:
        use_grey=lambda wildcards: use_grey(config, wildcards)
    run:
        if use_grey:
            shell(("zcat {input.black} | cat - {input.grey} | "
                   "    samtools view -U {output} -L /dev/stdin {input.bam} "
                   "> test"))
        else:
            shell(("zcat {input.black} | "
                   "    samtools view -U {output} -L /dev/stdin {input.bam} "
                   "> test"))

rule filter_blackgrey:
    input:
        bam='{outdir}/{genome}/mapping/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam',
        grey=lambda wildcards: get_greylist(config, wildcards),
        black=lambda wildcards: config['blacklist'][wildcards.genome]
    output:
        '{outdir}/{genome}/filtered/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam'
    params:
        use_grey=lambda wildcards: use_grey(config, wildcards)
    wildcard_constraints:
        target='[^_]+',
        sample='[^_]+',
        rep='r[0-9]+'
    run:
        if use_grey:
            shell(("zcat {input.black} | cat - {input.grey} | "
                   "    samtools view -U {output} -L /dev/stdin {input.bam} "
                   "> test"))
        else:
            shell(("zcat {input.black} | "
                   "    samtools view -U {output} -L /dev/stdin {input.bam} "
                   "> test"))


rule generate_greylist:
    input:
        '{outdir}/mapping/control/{srr}.bam'
    output:
        '{outdir}/greylist/{srr}-greystats.csv',
        '{outdir}/greylist/{srr}-greydepth.tsv',
        '{outdir}/greylist/{srr}-grey.bed'
    params:
        out='{outdir}/greylist/'
    shell:
        "chipseq-greylist --outdir {params.out} {input}"


ruleorder: mergeCtrl > markdup

rule mergeCtrl:
    input:
        lambda wildcards: ['%s/mapping/control/%s.bam' % (wildcards.outdir, srr_id)
                           for srr_id in wildcards.id_list.split('_')]
    output:
        '{outdir}/mapping/control/{id_list, .*_.*}.bam'
    threads:
        10
    shell:
        "sambamba merge -t {threads} {output} {input}"

rule index:
    input:
        '{outdir}/filtered/{folder}/{file}.bam'
    output:
        '{outdir}/filtered/{folder}/{file}.bam.bai'
    threads:
        5
    shell:
        "sambamba index -t {threads} {input}"




def keep_duplicates(config, wildcards, is_control=False):
    if is_control:
        for ct in config['experiment']:
            for exp in config['experiment'][ct]:
                for t in config['experiment'][ct][exp]:
                    for s in config['experiment'][ct][exp][t]:
                        sample_dict = config['experiment'][ct][exp][t][s]
                        if wildcards.srr_id in sample_dict['control']:
                            keep_dup = sample_dict['keep_duplicates']
    else:
        celltype_dict = config['experiment'][wildcards.celltype]
        target_dict = celltype_dict[wildcards.experiment][wildcards.target]
        keep_dup =  target_dict[wildcards.sample]['keep_duplicates']
    return(keep_dup)

def markdup(keepdup, input, output):
    if keepdup:
        shell("mv {input} {output}")
    else:
        shell("sambamba markdup -r {input} {output} ")

rule markdup:
    input:
        '{outdir}/mapping/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam.tmp'
    output:
        '{outdir}/mapping/{celltype}/{experiment}/{target}_{sample}_{rep}_{srr_id}.bam'
    params:
        keepdup=lambda wildcards: keep_duplicates(config, wildcards)
    threads:
        10
    run:
        markdup(params.keepdup, input, output)

rule markdup_ctrl:
    input:
        '{outdir}/mapping/control/{srr_id}.bam.tmp'
    output:
        '{outdir}/mapping/control/{srr_id}.bam'
    params:
        keepdup=lambda wildcards: keep_duplicates(config, wildcards,
                                                  is_control=True)
    threads:
        10
    run:
        markdup(params.keepdup, input, output)

def run_align(input, threads, aligner, index, min_mapq, output, log):
    if aligner == 'bowtie2':
        if len(input) is 1:
            bowtie=("bowtie2 --no-unal -p {threads} --met-file {log} "
                    "-x {index} -U {input}")
        else:
            bowtie=("bowtie2 --no-unal -p {threads}"
                    "        -x {index} -1 {input[0]} "
                    "        -2 {input[1]} --met-file {log} "
                    "| awk '{{if ($7==\"=\" || $1 ~ /^@/)"
                    "                               {{print $0}}}}'")
        view = ("sambamba view -S -F \"mapping_quality >= {min_mapq}\" -f bam "
                "--compression-level=0 /dev/stdin ")
        sort = "sambamba sort -o {output} --compression-level=0 /dev/stdin "
        shell(' | '.join((bowtie, view,  sort)))
    elif aligner == 'bwa':
        if len(input) is 1:
            bowtie=("bwa mem -t {threads} {index} {input} ")
        else:
            bowtie=("bwa mem -t {threads} {index} {input}  | "
                    "awk '{{if ($7==\"=\" || $1 ~ /^@/) {{print $0}}}}'")
        view = ("sambamba view -S -F \"mapping_quality >= {min_mapq}\" -f bam "
                "--compression-level=0 /dev/stdin ")
        sort = "sambamba sort -o {output} --compression-level=0 /dev/stdin "
        shell(' | '.join((bowtie, view,  sort)))


def get_sample_dict(config, wildcards, is_control=False):
    if is_control:
        for ct in config['experiment']:
            for exp in config['experiment'][ct]:
                for t in config['experiment'][ct][exp]:
                    for s in config['experiment'][ct][exp][t]:
                        sample_dict = config['experiment'][ct][exp][t][s]
                        if wildcards.srr_id in sample_dict['control']:
                            celltype = ct
                            experiment = exp
                            target = t
                            sample = s
                            rep = sample_dict['control'].index(wildcards.srr_id)
    else:
        celltype= wildcards.celltype
        experiment = wildcards.experiment
        target = wildcards.target
        sample = wildcards.sample
        rep = int(wildcards.rep.replace('r', '')) - 1

    sample_dict = config['experiment'][celltype][experiment][target][sample]
    return(sample_dict)



def get_align_input(config, wildcards, is_control=False):
    sample_dict = get_sample_dict(config, wildcards, is_control)
    if sample_dict['source'] in ["GEO", "ENCODE"]:
        if sample_dict['is_paired']:
            regex_list = ['%s/raw_data/%s_1.fastq.gz',
                          '%s/raw_data/%s_2.fastq.gz']
        else:
            regex_list = ['%s/raw_data/%s.fastq.gz']
        input_list = [regex % (wildcards.outdir, wildcards.srr_id)
                      for regex in regex_list]
    elif sample_dict['source'] == "local":
        if wildcards.srr_id in search_dict:
            srr_id = search_dict[wildcards.srr_id]
        else:
            srr_id = wildcards.srr_id
        fastq_list = glob.glob('/'.join((config['forge'], '**/*.fastq.gz')),
                               recursive=True)
        input_list = [fastq for fastq in fastq_list
                      if srr_id in fastq]
        if sample_dict['is_paired']:
            if 'R2' in input_list[0] and 'R1' in input_list[1]:
                input_list = [input_list[1], input_list[0]]
    return(input_list)



def get_aligner(config, wildcards, is_control=False):
    sample_dict = get_sample_dict(config, wildcards, is_control)
    return(sample_dict['aligner'])

def get_aligner_index(config, wildcards, is_control=False):
    aligner = get_aligner(config, wildcards, is_control)
    return(config['aligner_index'][aligner][wildcards.genome])


rule align_chip:
    input:
        lambda wildcards: get_align_input(config, wildcards)
    params:
        aligner=lambda wildcards: get_aligner(config, wildcards),
        index=lambda wildcards: get_aligner_index(config, wildcards),
        min_mapq=config['min_mapq']
    output:
        temp('{outdir}/{genome}/mapping/{celltype}/{experiment}/'
             '{target}_{sample}_{rep}_{srr_id}.bam.tmp')
    log:
        ('{outdir}/{genome}/log/mapping/{celltype}/{experiment}/'
         '{target}_{sample}_{rep}_{srr_id}.bam.tmp')
    threads:
        10
    wildcard_constraints:
        target='[^_]+',
        sample='[^_]+',
        rep='r[0-9]+'
    run:
        run_align(input, threads, params.aligner, params.index, params.min_mapq,
                  output, log)

rule align_control:
    input:
        lambda wildcards: get_align_input(config, wildcards, is_control=True)
    params:
        aligner=lambda wildcards: get_aligner(config, wildcards, is_control=True),
        index=lambda wildcards: get_aligner_index(config, wildcards, is_control=True),
        min_mapq=config['min_mapq']
    output:
        '{outdir}/{genome}/mapping/control/{srr_id, [^_]+}.bam.tmp'
    threads:
        10
    log:
        '{outdir}/{genome}/log/mapping/control/{srr_id, [^_]+}.txt'
    run:
        run_align(input, threads, params.aligner, params.index, params.min_mapq,
                  output, log)



ruleorder: download_paired_encode > download_single_encode
ruleorder: download_paired_encode > download_paired_sra

ruleorder: download_single_encode > download_single_sra
ruleorder: download_single_encode > download_paired_sra

ruleorder: download_paired_sra > download_single_sra

rule download_paired_sra:
    input: '{outdir}/raw_data/{srr_id}_prefetch'
    output:
        '{outdir}/raw_data/{srr_id}_1.fastq.gz',
        '{outdir}/raw_data/{srr_id}_2.fastq.gz'
    params:
        srr_id='{srr_id}',
        out='{outdir}/raw_data/'
    threads: 5
    shell:
        "parallel-fastq-dump --split-3 --outdir {params.out} --gzip "
        "                    --sra-id {params.srr_id} --threads {threads}"

rule download_single_sra:
    input: '{outdir}/raw_data/{srr_id}_prefetch'
    output: '{outdir}/raw_data/{srr_id}.fastq.gz'
    params:
        srr_id='{srr_id}',
        out='{outdir}/raw_data/'
    threads: 5
    shell:
        "parallel-fastq-dump --outdir {params.out} --gzip "
        "                    --sra-id {params.srr_id} --threads {threads}"

def get_encode_pair(config, wildcards):
    for ct in config['experiment']:
        for exp in config['experiment'][ct]:
            for t in config['experiment'][ct][exp]:
                for s in config['experiment'][ct][exp][t]:
                    sample_dict = config['experiment'][ct][exp][t][s]
                    if wildcards.enc_id in sample_dict['treatment']:
                        i = sample_dict['treatment'].index(wildcards.enc_id)
                        return(sample_dict['treatment2'][i])
                    elif wildcards.enc_id in sample_dict['control']:
                        i = sample_dict['control'].index(wildcards.enc_id)
                        return(sample_dict['control2'][i])


rule download_paired_encode:
    output:
        '{outdir}/raw_data/{enc_id}_1.fastq.gz',
        '{outdir}/raw_data/{enc_id}_2.fastq.gz'
    params:
        http=config['encode_http'],
        enc_id="{enc_id}",
        enc_id2=lambda wildcards: get_encode_pair(config, wildcards)
    wildcard_constraints:
        enc_id="ENCFF.+"
    run:
        pattern = [params.http.format(enc_id=params.enc_id),
                   params.http.format(enc_id=params.enc_id2)]

        shell("wget -O {output[0]} {pattern[0]}; "
              "wget -O {output[1]} {pattern[1]}")

rule download_single_encode:
    output: '{outdir}/raw_data/{enc_id}.fastq.gz'
    params:
        http=config['encode_http'],
        enc_id="{enc_id}"
    wildcard_constraints:
        enc_id="ENCFF.+"
    run:
        pattern = params.http.format(enc_id=params.enc_id)
        shell("wget -O {output} {pattern}")


rule prefetch_sra:
    output:
        temp('{outdir}/raw_data/{srr_id}_prefetch')
    params:
        srr_id='{srr_id}',
    shell:
        "prefetch {params.srr_id}; "
        "touch {output}"
